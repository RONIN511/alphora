"""
Internet Search Agent - äº’è”ç½‘æœç´¢æ™ºèƒ½ä½“

ä½¿ç”¨åšæŸ¥ Web Search API æä¾›è”ç½‘æœç´¢èƒ½åŠ›ã€‚
æ–‡æ¡£ï¼šhttps://open.bochaai.com/

ä½¿ç”¨ç¤ºä¾‹:
    from alphora_community.agents.internet_search import InternetSearchAgent
    
    agent = InternetSearchAgent(api_key="your-api-key")
    result = await agent.search_internet("æœ€æ–°AIæ–°é—»")
"""

import os
from typing import Optional, Literal

from alphora.agent import BaseAgent


class InternetSearchAgent(BaseAgent):
    """
    äº’è”ç½‘æœç´¢æ™ºèƒ½ä½“
    
    ä½¿ç”¨åšæŸ¥ Web Search API æœç´¢äº’è”ç½‘ä¿¡æ¯ã€‚
    
    Attributes:
        api_key: åšæŸ¥ API Key
        api_endpoint: API ç«¯ç‚¹åœ°å€
    """

    API_ENDPOINT = "https://api.bochaai.com/v1/web-search"

    def __init__(self, api_key: Optional[str] = None, **kwargs):
        """
        åˆå§‹åŒ–æœç´¢æ™ºèƒ½ä½“

        Args:
            api_key: åšæŸ¥ API Keyï¼Œä¸ä¼ åˆ™ä»ç¯å¢ƒå˜é‡ BOCHA_API_KEY è·å–
            **kwargs: ä¼ é€’ç»™ BaseAgent çš„å‚æ•°
        """
        super().__init__(**kwargs)
        self._api_key = api_key or os.getenv("BOCHA_API_KEY")

    def set_api_key(self, api_key: str):
        """è®¾ç½® API Key"""
        self._api_key = api_key

    async def search_internet(
        self,
        query: str,
        count: int = 8,
        freshness: Literal["noLimit", "oneDay", "oneWeek", "oneMonth", "oneYear"] = "noLimit"
    ) -> str:
        """
        æ‰§è¡Œäº’è”ç½‘å®æ—¶æœç´¢ï¼Œè·å–æœ€æ–°èµ„è®¯ã€äº‹å®éªŒè¯æˆ–ç‰¹å®šé¢†åŸŸçš„çŸ¥è¯†è¡¥å……ã€‚

        ã€æ ¸å¿ƒåŸåˆ™ï¼šèšç„¦ä¸æ‹†è§£ã€‘
        1. Query å¿…é¡»å…·ä½“ä¸”èšç„¦ï¼Œé¿å…å®½æ³›çš„é€šç”¨è¯æ±‡
        2. å¤æ‚éœ€æ±‚åº”æ‹†è§£ä¸ºå¤šæ¬¡æœç´¢

        ã€ä½¿ç”¨åœºæ™¯ã€‘
        - æŸ¥è¯¢å®æ—¶ä¿¡æ¯ï¼šæ–°é—»ã€è‚¡ä»·ã€å¤©æ°”ã€èµ›äº‹æ¯”åˆ†ç­‰
        - æŸ¥æ‰¾æœ€æ–°èµ„è®¯ï¼šæ”¿ç­–æ³•è§„ã€äº§å“å‘å¸ƒã€è¡Œä¸šåŠ¨æ€
        - éªŒè¯äº‹å®ï¼šæ ¸å®æŸä¸ªè¯´æ³•æˆ–æ•°æ®æ˜¯å¦å‡†ç¡®
        - è¡¥å……çŸ¥è¯†ï¼šè·å–è®­ç»ƒæ•°æ®ä¹‹å¤–çš„æ–°çŸ¥è¯†

        Args:
            query: æœç´¢å…³é”®è¯æˆ–é—®é¢˜ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€
            count: è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤ 8 æ¡ï¼Œæœ€å¤š 20 æ¡
            freshness: æ—¶é—´èŒƒå›´è¿‡æ»¤
                - "noLimit": ä¸é™æ—¶é—´ï¼ˆé»˜è®¤ï¼‰
                - "oneDay": æœ€è¿‘ä¸€å¤©
                - "oneWeek": æœ€è¿‘ä¸€å‘¨
                - "oneMonth": æœ€è¿‘ä¸€ä¸ªæœˆ
                - "oneYear": æœ€è¿‘ä¸€å¹´

        Returns:
            æ ¼å¼åŒ–çš„æœç´¢ç»“æœï¼ŒåŒ…å«æ ‡é¢˜ã€æ¥æºã€æ‘˜è¦ã€é“¾æ¥ç­‰
        """
        if not self._api_key:
            return "âŒ æœªé…ç½®åšæŸ¥ API Keyï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ BOCHA_API_KEY æˆ–è°ƒç”¨ set_api_key()"

        try:
            import httpx
        except ImportError:
            return "âŒ éœ€è¦å®‰è£… httpx: pip install httpx"

        headers = {
            "Authorization": f"Bearer {self._api_key}",
            "Content-Type": "application/json"
        }

        payload = {
            "query": query,
            "count": min(count, 20),
            "freshness": freshness,
            "summary": True,
        }

        if self.stream:
            await self.stream.astream_message(content=f"ğŸ” æ­£åœ¨æœç´¢ï¼š{query}\n\n", interval=0.01)

        try:
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.post(
                    self.API_ENDPOINT,
                    headers=headers,
                    json=payload
                )
                response.raise_for_status()
                data = response.json()
        except httpx.TimeoutException:
            return "âŒ æœç´¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
        except httpx.HTTPStatusError as e:
            return f"âŒ æœç´¢è¯·æ±‚å¤±è´¥ï¼šHTTP {e.response.status_code}"
        except Exception as e:
            return f"âŒ æœç´¢å‡ºé”™ï¼š{str(e)}"

        # æµå¼è¾“å‡ºç®€æ´ç»“æœç»™ç”¨æˆ·
        if self.stream:
            await self._stream_to_user(data)

        # è¿”å›ç»™ LLM çš„è¯¦ç»†ç»“æœ
        return self._format_results_for_llm(query, data)

    async def _stream_to_user(self, data: dict):
        """æµå¼è¾“å‡ºç»™ç”¨æˆ·çœ‹çš„ç®€æ´å†…å®¹"""
        response_data = data.get("data", {})
        web_pages = response_data.get("webPages", {}).get("value", [])

        if not web_pages:
            await self.stream.astream_message(content="æœªæ‰¾åˆ°ç›¸å…³ç»“æœ\n", interval=0.01)
            return

        await self.stream.astream_message(content="**æœç´¢ç»“æœ**\n\n", interval=0.01)

        for i, page in enumerate(web_pages[:6], 1):
            title = page.get("name", "æ— æ ‡é¢˜")
            url = page.get("url", "")
            site_name = page.get("siteName", "")
            date = page.get("datePublished", "")

            source_info = site_name
            if date:
                source_info += f" Â· {date[:10]}"

            await self.stream.astream_message(
                content=f"**{i}. [{title}]({url})**\n",
                interval=0.01
            )
            if source_info:
                await self.stream.astream_message(
                    content=f"   {source_info}\n\n",
                    interval=0.01
                )

    def _format_results_for_llm(self, query: str, data: dict) -> str:
        """æ ¼å¼åŒ–ç»™ LLM ä½¿ç”¨çš„è¯¦ç»†æœç´¢ç»“æœ"""
        lines = [f"æœç´¢è¯ï¼š{query}", ""]

        response_data = data.get("data", {})
        web_pages = response_data.get("webPages", {}).get("value", [])

        if not web_pages:
            return "æœªæ‰¾åˆ°ç›¸å…³ç»“æœ"

        lines.append(f"å…± {len(web_pages)} æ¡ç»“æœï¼š\n")

        for i, page in enumerate(web_pages, 1):
            title = page.get("name", "æ— æ ‡é¢˜")
            url = page.get("url", "")
            site_name = page.get("siteName", "æœªçŸ¥æ¥æº")
            snippet = page.get("snippet", "")
            summary = page.get("summary", "")
            date = page.get("datePublished", "")

            lines.append(f"ã€{i}ã€‘{title}")
            lines.append(f"æ¥æºï¼š{site_name}" + (f" | {date[:10]}" if date else ""))

            content = summary or snippet
            if content:
                if len(content) > 500:
                    content = content[:500] + "..."
                lines.append(f"å†…å®¹ï¼š{content}")

            lines.append(f"é“¾æ¥ï¼š{url}")
            lines.append("")

        return "\n".join(lines)
